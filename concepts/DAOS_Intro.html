
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><meta name="description" content=":warning: Warning: DAOS is under heavy development. Use at your own risk. The Distributed Asynchronous Object Storage (DAOS) stack provides a new storage paradigm for Exascale computing and Big Data. ..." /><meta name="copyright" content="(C) Copyright 2017" /><meta name="DC.rights.owner" content="(C) Copyright 2017" /><meta name="DC.Type" content="topic" /><meta name="DC.Title" content="Distributed Asynchronous Object Storage" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="distributed_asynchronous_object_storage" /><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css?buildId=2017033118"><!----></link><title>Distributed Asynchronous Object Storage</title><!--  Generated with Oxygen version 19.0, build number 2017033118.  --><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css?buildId=2017033118"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/skins/skin.css?buildId=2017033118" /><script type="text/javascript"><!--
            
            var prefix = "../index.html";
            
            --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-3.1.1.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js?buildId=2017033118"><!----></script></head>
<body onload="highlightSearchTerm()" class="frmBody" id="distributed_asynchronous_object_storage">
<header role="banner"><table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td style="width:75%;"><span class="topic_breadcrumb_links"></span></td><td><span id="topic_navigation_links" class="navheader"></span></td></tr></tbody></table></header><main role="main"><article role="article" aria-labelledby="ariaid-title1"><h1 class="title topictitle1" id="ariaid-title1">Distributed Asynchronous Object Storage</h1>
<div class="body"><blockquote class="lq"><p class="p">:warning: <strong class="ph b">Warning:</strong> DAOS is under heavy development. Use at your own risk.</p>
</blockquote>
</div>
<article class="topic nested1" aria-labelledby="ariaid-title2" id="what_is_daos"><h2 class="title topictitle2" id="ariaid-title2">What is DAOS?</h2>
<div class="body"><p class="p">The Distributed Asynchronous Object Storage (DAOS) stack provides a new storage paradigm for Exascale computing and Big Data. DAOS is an open-source storage stack designed from the ground up to exploit NVRAM and NVMe storage technologies with integrated fabric. It provides ultra-fine grained I/O by using a persistent memory storage model for byte-granular data &amp; metadata combined with NVMe storage for bulk data, all this with end-to-end OS bypass to guarantee ultra-low latency. The DAOS stack aims at increasing data velocity by several orders of magnitude over conventional storage stacks and providing extreme scalability and resilience.</p>
<p class="p">The essence of the DAOS storage model is a key-value store interface over which specific data models can be implemented. A DAOS object is effectively a table of records that are addressed through a flexible multi-level key allowing fine-grain control over colocation of related data. Objects are collected into manageable units called containers. DAOS provides scalable distributed transactions across all objects of a container guaranteeing data consistency and automated rollback on failure to I/O middleware libraries and applications. The DAOS transaction mechanism supports complex workflows with native producer/consumer pipeline in which concurrent consumers do not block producers and consumers receive notification on complete atomic updates and see a consistent snapshot of data..</p>
<p class="p">For both performance and resilience, DAOS objects support multiple distribution and redundancy schemas with fully automated and distributed recovery on storage failure. DAOS uses declustered replication and/or erasure coding over homogeneous shared-nothing servers and provides a lockless consistency model at arbitrary alignment.</p>
<p class="p">Finally, the DAOS stack abstracts multi-tier storage architecture and offers a unified storage model over which multiple top-level APIs will be developed. This includes domain-specific APIs like HDF5, SCiDB, ADIOS and high-level data models like HDFS, Spark and Graph A. A POSIX namespace encapsulation inside a DAOS container is also under consideration.</p>
</div>
</article>
<article class="topic nested1" aria-labelledby="ariaid-title3" id="project_history"><h2 class="title topictitle2" id="ariaid-title3">Project History</h2>
<div class="body"><p class="p">The project started back in 2012 with the Fast Forward Storage &amp; I/O program supported by the U.S. DoE in which a first DAOS prototype was implemented over the Lustre filesystem and ZFS. In 2015, a follow-on program called Extreme Scale Storage and I/O (ESSIO) continued the momentum with the development of a new standalone prototype fully in userspace that is the code base provided in this repository.</p>
</div>
</article>
<article class="topic nested1" aria-labelledby="ariaid-title4" id="motivations"><h2 class="title topictitle2" id="ariaid-title4">Motivations</h2>
<div class="body"><p class="p">The emergence of data-intensive applications in business, government and academia stretches the existing I/O models beyond limits. Modern I/O workloads feature an increasing proportion of metadata combined with misaligned and fragmented data. Conventional storage stacks deliver poor performance for these workloads by adding a lot of latency and introducing alignment constraints. The advent of affordable large-capacity persistent memory combined with an integrated fabric offers a unique opportunity to redefine the storage paradigm and support modern I/O workloads efficiently.</p>
<p class="p">This revolution requires a radical rethink of the complete storage stack. To unleash the full potential of this new technology, the new stack must embrace byte-granular shared-nothing interface from the ground up and be able to support massively distributed storage for which failure will be the norm, while preserving low latency and high bandwidth access over the fabric.</p>
<p class="p">DAOS is a complete I/O architecture that aggregates persistent memory and NVMe storage distributed across the fabric into globally-accessible object address spaces, providing consistency, availability and resiliency guarantees without compromising performance.</p>
</div>
</article>
<article class="topic nested1" aria-labelledby="ariaid-title5" id="license"><h2 class="title topictitle2" id="ariaid-title5">License</h2>
<div class="body"><p class="p">DAOS is open-sourced software licensed under the Apache License Version 2.0. Please see the <a class="xref" href="LICENSE">LICENSE</a> &amp; <a class="xref" href="NOTICE">NOTICE</a> files for more information.</p>
</div>
</article>
<article class="topic nested1" aria-labelledby="ariaid-title6" id="software_requirements"><h2 class="title topictitle2" id="ariaid-title6">Software Requirements</h2>
<div class="body"><p class="p">DAOS requires a C99-capable compiler and the scons build tool. In addition, the DAOS stack is proud to leverage the following open source projects:</p>
<ul class="ul"><li class="li"><a class="xref" href="https://github.com/daos-stack/cart" target="_blank">CaRT</a> that relies on both <a class="xref" href="https://mercury-hpc.github.io" target="_blank">Mercury</a> and <a class="xref" href="http://cci-forum.com/wp-content/uploads/2015/12/cci-0.3.0.tar.gz" target="_blank">CCI</a> for lightweight network transport and <a class="xref" href="https://github.com/pmix/master" target="_blank">PMIx</a> for process set management. See the CaRT repository for more information on how to build the CaRT library.</li>
<li class="li"><a class="xref" href="https://github.com/pmem/nvml.git" target="_blank">NVML</a> for persistent memory programming..</li>
<li class="li"><a class="xref" href="https://github.com/pmodels/argobots" target="_blank">Argobots</a> for thread management.</li>
</ul>
<p class="p">If all the software dependencies listed above are already satisfied, then just type "scons" in the top source directory to build the DAOS stack. Otherwise, please follow the instructions in the section below to build DAOS with all the dependencies.</p>
<p class="p">In the near future, the DAOS stack will also rely on:</p>
<ul class="ul"><li class="li"><a class="xref" href="http://spdk.io" target="_blank">SPDK</a> for NVMe device access and management</li>
<li class="li"><a class="xref" href="https://github.com/01org/isa-l" target="_blank">ISA-L</a> for checksum and erasure code computation</li>
</ul>
</div>
</article>
<article class="topic nested1" aria-labelledby="ariaid-title7" id="building_daos"><h2 class="title topictitle2" id="ariaid-title7">Building DAOS</h2>
<div class="body"><p class="p">The below instructions have been verified with CentOS. Installations on other Linux distributions might be similar with some variations. Please contact us in our <a class="xref" href="https://groups.google.com/forum/#!forum/daos-users" target="_blank">Google group</a> if running into issues.</p>
<p class="p">Pre-install dependencies. Please install the following Red Hat Enterprise Linux RPM software packages (or) equivalent for other distros:</p>
<pre class="pre codeblock"><code># yum -y install epel-release scons cmake doxygen gcc-c++
# yum -y install boost-devel libevent-devel librdmacm-devel
# yum -y install libtool-ltdl-devel libuuid-devel openssl-devel
# yum -y install libcmocka libcmocka-devel pandoc&lt;/&gt;</code></pre><p class="p">If no Cmocka RPMs are available, please install from <a class="xref" href="https://cmocka.org/files/1.1/cmocka-1.1.0.tar.xz" target="_blank">source</a> as detailed below:</p>
<pre class="pre codeblock"><code># tar xvf cmocka-1.1.0.tar.xz
# cd cmocka
# mkdir build &amp;&amp; cd build &amp;&amp; cmake -DCMAKE_INSTALL_PREFIX=/usr -DCMAKE_BUILD_TYPE=Debug .. &amp;&amp; make &amp;&amp; sudo make install</code></pre><p class="p">Moreover, please make sure all the auto tools listed below are at the appropriate versions.</p>
<pre class="pre codeblock"><code>m4 (GNU M4) 1.4.16
flex 2.5.37
autoconf (GNU Autoconf) 2.69
automake (GNU automake) 1.13.4
libtool (GNU libtool) 2.4.2</code></pre><p class="p">(b) Checking out the DAOS source code</p>
<pre class="pre codeblock"><code># git clone https://github.com/daos-stack/daos.git</code></pre><p class="p">This clones the DAOS git repository (path referred as \${daospath} below). Then initialize the submodules with:</p>
<pre class="pre codeblock"><code># cd ${daospath}
# git submodule init
# git submodule update</code></pre><p class="p">(c) Building all dependencies automatically</p>
<p class="p">Invoke scons with the following parameters:</p>
<pre class="pre codeblock"><code># scons --build-deps=yes install</code></pre><p class="p">By default, all software will be installed under \${daospath}/install. The TARGET_PREFIX= option can be added to the command line above to specify an alternative installation path.</p>
<p class="p">(d) Environment setup</p>
<p class="p">Once built, the environment must be modified to search for binaries, libraries and header files in the installation path. This step is not required if standard locations (e.g. /bin, /sbin, /usr/lib, ...) are used.</p>
<pre class="pre codeblock"><code>LD_LIBRARY_PATH=${daospath}/install/lib:$LD_LIBRARY_PATH
LD_LIBRARY_PATH=${daospath}/install/lib/daos_srv/:$LD_LIBRARY_PATH
CPATH=${daospath}/install/include/:$CPATH
PATH=${daospath}/install/bin/:${daospath}/install/sbin:$PATH
export LD_LIBRARY_PATH CPATH PATH</code></pre><p class="p">If required, \${daospath}/install must be replaced with the alternative path specified through PREFIX. The network type to use as well the debug log location can be selected as follows:</p>
<pre class="pre codeblock"><code>CCI_CONFIG=${daospath}/install/etc/cci.ini
CRT_PHY_ADDR_STR="cci+tcp", for infiniband use "cci+verbs"
DD_LOG=${daosdebugpath}, /tmp/daos.log by default.
export CCI_CONFIG CRT_PHY_ADDR_STR DD_LOG</code></pre><p class="p">Additionally, one might want to set the following environment variables to work around an Argobot issue:</p>
<pre class="pre codeblock"><code>ABT_ENV_MAX_NUM_XSTREAMS=100
ABT_MAX_NUM_XSTREAMS=100
export ABT_ENV_MAX_NUM_XSTREAMS ABT_MAX_NUM_XSTREAMS</code></pre></div>
</article>
<article class="topic nested1" aria-labelledby="ariaid-title8" id="using_daos"><h2 class="title topictitle2" id="ariaid-title8">Using DAOS</h2>
<div class="body"><p class="p">DAOS uses orterun(1) for scalable process launch. The list of storage nodes can be specified in an host file (referred as \${hostfile}). The DAOS server and the application can be started seperately, but must share an URI file (referred as \${urifile}) to connect to each other. In addition, the DAOS server must be started with the --enable-recovery option to support server failure. See the orterun(1) man page for additional options.</p>
<p class="p">(a) Starting the DAOS server</p>
<p class="p">On each storage node, the DAOS server will use /mnt/daos as the storage backend that must be configured, for the time being, as a tmpfs filesystem. To start the DAOS server, run:</p>
<pre class="pre codeblock"><code>orterun -np &lt;num_servers&gt; --hostfile ${hostfile} --enable-recovery --report-uri ${urifile} daos_server</code></pre><p class="p">By default, the DAOS server will use all the cores available on the storage server. You can limit the number of execution streams with the -c #cores_to_use option.</p>
<p class="p">(b) Creating/destroy a DAOS pool</p>
<p class="p">A DAOS pool can be created and destroyed through the DAOS management API (see daos_mgmt.h). We also provide an utility called dmg to manage storage pools from the command line.</p>
<p class="p">To create a pool:</p>
<pre class="pre codeblock"><code>orterun --ompi-server file:${urifile} dmg create --size=xxG</code></pre><p class="p">This creates a pool distributed across the DAOS servers with a target size on each server of xxGB. The UUID allocated to the newly created pool is printed to stdout (referred as \${pooluuid}).</p>
<p class="p">To destroy a pool:</p>
<pre class="pre codeblock"><code>orterun --ompi-server file:${urifile} dmg destroy --pool=${pooluuid}</code></pre><p class="p">(c) Building applications or I/O middleware against the DAOS library</p>
<p class="p">Include the daos.h header file in your program and link with -Ldaos. Examples are available under src/tests.</p>
<p class="p">(d) Running applications</p>
<pre class="pre codeblock"><code>orterun -np &lt;num_clients&gt; --hostfile ${hostfile_cli} --ompi-server file:$urifile ${application} eg., ./daos_test</code></pre></div>
</article>
<article class="topic nested1" aria-labelledby="ariaid-title9" id="setup_daos_for_development"><h2 class="title topictitle2" id="ariaid-title9">Setup DAOS for Development</h2>
<div class="body"><p class="p">Setting up DAOS for development would be simpler by building with TARGET_PREFIX for all the dependencies and use PREFIX for your custom DAOS installation from your sandbox. Once the submodule has been initialized and updated,</p>
<pre class="pre codeblock"><code>scons --build-deps=yes PREFIX=$(daos_prefix_path} TARGET_PREFIX=${daos_prefix_path}/opt install</code></pre><p class="p">With this type of installation each individual component is built into a different directory. Installing the components into seperate directories allow to upgrade the components individually using --update-prereq={component_name}. This requires change to the environment configuration from before.</p>
<pre class="pre codeblock"><code>ARGOBOTS=${daos_prefix_path}/opt/argobots
CART=${daos_prefix_path}/opt/cart
CCI=${daos_prefix_path}/opt/cci
HWLOC=${daos_prefix_path}/opt/hwloc
MERCURY=${daos_prefix_path}/opt/mercury
NVML=${daos_prefix_path}/opt/nvml
OMPI=${daos_prefix_path}/opt/ompi
OPA=${daos_prefix_path}/opt/openpa
PMIX=${daos_prefix_path}/opt/pmix

PATH=$CART/bin/:$CCI/bin/:$HWLOC/bin/:$PATH
PATH=$MERCURY/bin/:$NVML/bin/:$OMPI/bin/:$OPA/bin/:$PMIX/bin/:$PATH
PATH=${daos_prefix_path}/bin/:$PATH

LD_LIBRARY_PATH=/usr/lib64/:$ARGOBOTS/lib/:$CART/lib/:$CCI/lib/:$HWLOC/lib/:$LD_LIBRARY_PATH
LD_LIBRARY_PATH=$MERCURY/lib/:$NVML/lib/:$OMPI/lib/:$OMPI/lib/openmpi/:$OPA/lib/:$PMIX/lib/:$LD_LIBRARY_PATH
LD_LIBRARY_PATH=${daos_prefix_path}/lib/:${daos_prefix_path}/lib/daos_srv/:$LD_LIBRARY_PATH</code></pre><p class="p">(a) Using prebuilt dependencies</p>
<p class="p">With an installation complete with TARGET_PREFIX, the PREBUILT_PREFIX functionality can be used to reuse prebuilt dependencies.
On your new sandbox after 'git submodule init and git submodule update'</p>
<pre class="pre codeblock"><code>scons PREBUILT_PREFIX=${daos_prefix_path}/opt PREFIX=${daos_custom_install} install</code></pre><p class="p">With this approach only daos would get built using the prebuilt dependencies in ${daos_prefix_path}/opt and the PREBUILT_PREFIX and PREFIX would get saved for future compilations. So, after the first time, during development, a mere "scons" and "scons install" would suffice for compiling changes to daos source code.</p>
</div>
</article>
<article class="topic nested1" aria-labelledby="ariaid-title10" id="reporting_problems"><h2 class="title topictitle2" id="ariaid-title10">Reporting Problems</h2>
<div class="body"><p class="p">Please report any bugs through our <a class="xref" href="https://jira.hpdd.intel.com/projects/DAOS" target="_blank">issue tracker</a> with a test case to reproduce the issue (when applicable) and debug logs that should be compressed. DAOS debug logs are written by default to /tmp/daos.log, this can be modified by specifying a different path through DD_LOG. Similarly, the debug mask and subsystems are controlled by respectively the DD_MASK and DD_SUBSYS environment variables.</p>
</div>
</article>
<article class="topic nested1" aria-labelledby="ariaid-title11" id="contacts"><h2 class="title topictitle2" id="ariaid-title11">Contacts</h2>
<div class="body"><p class="p">For more information on DAOS, please post to our <a class="xref" href="https://groups.google.com/forum/#!forum/daos-users" target="_blank">Google group</a>.</p>
</div>
</article>
</article></main><footer role="contentinfo"><div class="navfooter"><!----></div><div class="footer" id="webhelp_copyright_information">Generated by<a class="oxyFooter" href="http://www.oxygenxml.com/xml_webhelp.html" target="_blank">
                            &lt;oXygen/&gt; XML WebHelp
                        </a></div></footer></body>
</html>